# rag.py
import os
import json
import shutil
import requests
from dotenv import load_dotenv
import chromadb
from typing import Dict, List, Optional
import google.generativeai as genai
from google.api_core.exceptions import ResourceExhausted


load_dotenv()

# Lazy loading iÃ§in global deÄŸiÅŸkenler
chroma_client = None
collection = None

def ensure_database_ready():
    """Production'da database'in hazÄ±r olduÄŸundan emin ol"""
    try:
        # Database durumunu kontrol et
        db_info = get_database_info()
        
        if "error" not in db_info and db_info.get('total_chunks', 0) > 0:
            print("âœ… Database hazÄ±r")
            return True
        
        # Database boÅŸsa otomatik kur
        print("ğŸ“‹ Database boÅŸ, otomatik kurulum baÅŸlatÄ±lÄ±yor...")
        from setup_database import setup_database_if_needed
        return setup_database_if_needed()
        
    except Exception as e:
        print(f"âš ï¸ Database kontrol hatasÄ±: {e}")
        return False


def initialize_chroma():
    """ChromaDB'yi lazy loading ile baÅŸlat - GÃœNCELLENEN VERSÄ°YON"""
    global chroma_client, collection
    if chroma_client is None:
        try:
            # Absolute path kullan - working directory sorunlarÄ±nÄ± Ã¶nlemek iÃ§in
            current_dir = os.path.dirname(os.path.abspath(__file__))
            db_path = os.path.join(current_dir, "db")
            
            print(f"ğŸ” ChromaDB initialize - current_dir: {current_dir}")
            print(f"ğŸ” ChromaDB initialize - db_path: {db_path}")
            print(f"ğŸ” ChromaDB initialize - db_path exists: {os.path.exists(db_path)}")
            
            chroma_client = chromadb.PersistentClient(path=db_path)
            # ArtÄ±k database'i silmiyoruz, mevcut koleksiyonu kullanÄ±yoruz
            collection = chroma_client.get_or_create_collection(name="medical_books")
            
            print(f"âœ… ChromaDB baÅŸarÄ±yla baÅŸlatÄ±ldÄ±")
        except Exception as e:
            print(f"âŒ ChromaDB initialization failed: {e}")
            import traceback
            traceback.print_exc()
            chroma_client = "error"
            collection = "error"
    return chroma_client, collection

def reset_globals():
    """Global deÄŸiÅŸkenleri sÄ±fÄ±rla"""
    global chroma_client, collection, llm
    chroma_client = None
    collection = None
    print("ğŸ”„ Global deÄŸiÅŸkenler sÄ±fÄ±rlandÄ±")

def reset_database():
    """Database'i sÄ±fÄ±rla (sadece setup sÄ±rasÄ±nda kullan)"""
    try:
        # Absolute path kullan
        current_dir = os.path.dirname(os.path.abspath(__file__))
        db_path = os.path.join(current_dir, "db")
        
        if os.path.exists(db_path):
            shutil.rmtree(db_path)
        print("âœ… Database sÄ±fÄ±rlandÄ±")
        
        # Global deÄŸiÅŸkenleri de sÄ±fÄ±rla
        global chroma_client, collection
        chroma_client = None
        collection = None
        
    except Exception as e:
        print(f"âŒ Database sÄ±fÄ±rlama hatasÄ±: {e}")

def load_book_to_db(specialty: str, json_file_path: str) -> bool:
    """Bir kitabÄ±n chunk'larÄ±nÄ± database'e yÃ¼kle"""
    try:
        # JSON dosyasÄ±nÄ± oku
        with open(json_file_path, 'r', encoding='utf-8') as f:
            chunks = json.load(f)
        
        # ChromaDB'yi baÅŸlat
        _, coll = initialize_chroma()
        if coll == "error":
            print(f"âŒ ChromaDB hatasÄ±")
            return False
        
        documents = []
        metadatas = []
        ids = []
        
        print(f"ğŸ“š {specialty} kitabÄ± yÃ¼kleniyor: {len(chunks)} chunk")
        
        for i, chunk in enumerate(chunks):
            # Unique ID oluÅŸtur
            chunk_id = f"{specialty}_{i}"
            
            # Document content
            content = chunk.get('content', chunk.get('text', ''))
            if not content:
                print(f"âš ï¸ BoÅŸ chunk atlanÄ±yor: {chunk_id}")
                continue
                
            documents.append(content)
            
            # Metadata oluÅŸtur
            metadata = {
                "specialty": specialty,
                "book_title": chunk.get('book_title', f"{specialty.title()} Medical Book"),
                "page_number": str(chunk.get('page_number', chunk.get('page', 'Unknown'))),
                "chunk_index": i,
                "source_type": "medical_textbook"
            }
            metadatas.append(metadata)
            ids.append(chunk_id)
        
        # Batch olarak database'e ekle
        if documents:
            coll.add(
                documents=documents,
                metadatas=metadatas,
                ids=ids
            )
            print(f"âœ… {specialty} baÅŸarÄ±yla yÃ¼klendi: {len(documents)} chunk")
            return True
        else:
            print(f"âŒ {specialty} iÃ§in hiÃ§ geÃ§erli chunk bulunamadÄ±")
            return False
            
    except Exception as e:
        print(f"âŒ {specialty} yÃ¼kleme hatasÄ±: {e}")
        return False

def load_all_medical_books(books_config: Dict[str, str]) -> Dict[str, bool]:
    """TÃ¼m kitaplarÄ± database'e yÃ¼kle"""
    results = {}
    
    print("ğŸš€ TÃ¼m medical kitaplar yÃ¼kleniyor...")
    print("=" * 50)
    
    for specialty, file_path in books_config.items():
        if os.path.exists(file_path):
            success = load_book_to_db(specialty, file_path)
            results[specialty] = success
        else:
            print(f"âŒ Dosya bulunamadÄ±: {file_path}")
            results[specialty] = False
    
    print("=" * 50)
    print("ğŸ“Š YÃ¼kleme Ã–zeti:")
    for specialty, success in results.items():
        status = "âœ… BaÅŸarÄ±lÄ±" if success else "âŒ HatalÄ±"
        print(f"  {specialty}: {status}")
    
    return results

def query_db_by_specialty(query: str, specialty: str = None, n_results: int = 3) -> Dict:
    """Specialty'ye gÃ¶re filtrelenmiÅŸ sorgu"""
    try:
        _, coll = initialize_chroma()
        if coll == "error":
            return {"documents": [], "metadatas": []}
        
        # Metadata filtreleme
        where_filter = None
        if specialty:
            where_filter = {"specialty": specialty}
        
        results = coll.query(
            query_texts=[query], 
            n_results=n_results,
            where=where_filter
        )
        
        return results
    except Exception as e:
        print(f"âŒ Database sorgu hatasÄ±: {e}")
        return {"documents": [], "metadatas": []}

def get_database_info() -> Dict:
    """Database bilgilerini getir"""
    try:
        _, coll = initialize_chroma()
        if coll == "error":
            return {"error": "ChromaDB kullanÄ±lamÄ±yor"}
        
        # TÃ¼m metadatalarÄ± al
        results = coll.get()
        
        if not results.get("metadatas"):
            return {"total_chunks": 0, "specialties": []}
        
        # Specialty'leri say
        specialties = {}
        for metadata in results["metadatas"]:
            specialty = metadata.get("specialty", "unknown")
            specialties[specialty] = specialties.get(specialty, 0) + 1
        
        return {
            "total_chunks": len(results["metadatas"]),
            "specialties": specialties,
            "available_books": list(specialties.keys())
        }
    except Exception as e:
        return {"error": f"Database bilgi alma hatasÄ±: {e}"}

def add_to_db(doc_id, content):
    """Eski API - geriye uyumluluk iÃ§in"""
    print("âš ï¸ add_to_db deprecated. Use load_book_to_db instead.")
    return False

def query_db(query):
    """Eski API - geriye uyumluluk iÃ§in"""
    results = query_db_by_specialty(query)
    if results.get("documents") and results["documents"][0]:
        return results["documents"][0][0]
    return ""


def ask_gemini_api(prompt: str, model_name: str = "models/gemini-1.5-flash-002", max_tokens=500, temperature=0.7) -> str:
    api_key = os.getenv("GEMINI_API_KEY")
    if not api_key:
        raise RuntimeError("Gemini API anahtarÄ± bulunamadÄ±. LÃ¼tfen .env dosyasÄ±nÄ± kontrol edin.")
    genai.configure(api_key=api_key)
    
    try:
        # Modeli baÅŸlat (Ã¶rneÄŸin gemini-pro kullanÄ±lÄ±yor)
        model = genai.GenerativeModel(model_name=model_name)

        # Prompt gÃ¶nder
        response = model.generate_content(
            prompt,
            generation_config={
                "temperature": temperature,
                "max_output_tokens": max_tokens
            }
        )

        return response.text.strip()

    except Exception as e:
        # EÄŸer hata mesajÄ±nda "429" veya kota aÅŸÄ±mÄ± ile ilgili bir ÅŸey varsa ResourceExhausted fÄ±rlat
        if "429" in str(e) or "quota" in str(e).lower():
            raise ResourceExhausted(str(e))
        # DiÄŸer hatalar iÃ§in genel exception
        raise

def answer_question(question: str, specialty: str = None, model: str = "models/gemini-1.5-flash-002") -> Dict:
    try:
        if "[ENDOCRINOLOGY]" in question:
            specialty = "endocrinology"
            question = question.replace("[ENDOCRINOLOGY]", "").strip()
        db_results = query_db_by_specialty(question, specialty, n_results=3)
        if not db_results.get("documents") or not db_results["documents"][0]:
            return {
                "answer": "ÃœzgÃ¼nÃ¼m, bu konuda bilgi bulamadÄ±m.",
                "source_metadata": None,
                "query_info": {
                    "specialty_filter": specialty,
                    "results_found": 0
                }
            }
        context = db_results["documents"][0][0]
        metadata = db_results["metadatas"][0][0] if db_results.get("metadatas") else {}
        prompt = f"""
Context: {context}

Question: {question}

Answer based on the medical context provided:
"""
        # Burada ask_gemini_api Ã§aÄŸrÄ±sÄ±nÄ± try-except ile sarmalÄ±yoruz:
        try:
            llm_answer = ask_gemini_api(prompt, model_name=model, max_tokens=500, temperature=0.7)
        except Exception as e:
            print(f"âŒ Inner exception in ask_gemini_api: {type(e).__name__} - {e}")
            # EÄŸer bu zaten ResourceExhausted ise yeniden fÄ±rlat
            if isinstance(e, ResourceExhausted):
                raise e
            # EÄŸer hata mesajÄ± iÃ§inde 429 veya quota geÃ§iyorsa yeniden sÄ±nÄ±flandÄ±r
            elif "429" in str(e) or "quota" in str(e).lower():
                print("ğŸš¨ answer_question: ResourceExhausted olarak sÄ±nÄ±flandÄ±rÄ±lÄ±yor.")
                raise ResourceExhausted(str(e))
            # DiÄŸer hatalarÄ± direkt fÄ±rlat
            raise e

        
        book_title = metadata.get("book_title", "Unknown")
        page_number = metadata.get("page_number", "Unknown")
        answer_with_source = f"This information is from {book_title}'s {page_number}th page:\n\n{llm_answer}"
        return {
            "answer": answer_with_source,
            "source_metadata": {
                "book_title": book_title,
                "page_number": page_number,
                "specialty": metadata.get("specialty", "Unknown")
            },
            "query_info": {
                "specialty_filter": specialty,
                "results_found": len(db_results["documents"][0])
            }
        }

    except ResourceExhausted as e:
    print(f"ğŸŸ¥ answer_question ResourceExhausted fÄ±rlatÄ±yor: {e}")
    raise
    
    except Exception as e:
        print(f"âŒ answer_question dÄ±ÅŸ hata: {type(e).__name__} - {e}")
        return {
            "answer": f"Bir hata oluÅŸtu: {str(e)}",
            "source_metadata": None,
            "query_info": None
        }


