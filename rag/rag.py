# rag.py
import os
import json
import shutil
import requests
from dotenv import load_dotenv
import chromadb
from typing import Dict, List, Optional
import google.generativeai as genai

load_dotenv()

# Lazy loading i√ßin global deƒüi≈ükenler
chroma_client = None
collection = None

def ensure_database_ready():
    """Production'da database'in hazƒ±r olduƒüundan emin ol"""
    try:
        # Database durumunu kontrol et
        db_info = get_database_info()
        
        if "error" not in db_info and db_info.get('total_chunks', 0) > 0:
            print("‚úÖ Database hazƒ±r")
            return True
        
        # Database bo≈üsa otomatik kur
        print("üìã Database bo≈ü, otomatik kurulum ba≈ülatƒ±lƒ±yor...")
        from setup_database import setup_database_if_needed
        return setup_database_if_needed()
        
    except Exception as e:
        print(f"‚ö†Ô∏è Database kontrol hatasƒ±: {e}")
        return False


def initialize_chroma():
    """ChromaDB'yi lazy loading ile ba≈ülat - G√úNCELLENEN VERSƒ∞YON"""
    global chroma_client, collection
    if chroma_client is None:
        try:
            # Absolute path kullan - working directory sorunlarƒ±nƒ± √∂nlemek i√ßin
            current_dir = os.path.dirname(os.path.abspath(__file__))
            db_path = os.path.join(current_dir, "db")
            
            print(f"üîç ChromaDB initialize - current_dir: {current_dir}")
            print(f"üîç ChromaDB initialize - db_path: {db_path}")
            print(f"üîç ChromaDB initialize - db_path exists: {os.path.exists(db_path)}")
            
            chroma_client = chromadb.PersistentClient(path=db_path)
            # Artƒ±k database'i silmiyoruz, mevcut koleksiyonu kullanƒ±yoruz
            collection = chroma_client.get_or_create_collection(name="medical_books")
            
            print(f"‚úÖ ChromaDB ba≈üarƒ±yla ba≈ülatƒ±ldƒ±")
        except Exception as e:
            print(f"‚ùå ChromaDB initialization failed: {e}")
            import traceback
            traceback.print_exc()
            chroma_client = "error"
            collection = "error"
    return chroma_client, collection

def reset_globals():
    """Global deƒüi≈ükenleri sƒ±fƒ±rla"""
    global chroma_client, collection, llm
    chroma_client = None
    collection = None
    print("üîÑ Global deƒüi≈ükenler sƒ±fƒ±rlandƒ±")

def reset_database():
    """Database'i sƒ±fƒ±rla (sadece setup sƒ±rasƒ±nda kullan)"""
    try:
        # Absolute path kullan
        current_dir = os.path.dirname(os.path.abspath(__file__))
        db_path = os.path.join(current_dir, "db")
        
        if os.path.exists(db_path):
            shutil.rmtree(db_path)
        print("‚úÖ Database sƒ±fƒ±rlandƒ±")
        
        # Global deƒüi≈ükenleri de sƒ±fƒ±rla
        global chroma_client, collection
        chroma_client = None
        collection = None
        
    except Exception as e:
        print(f"‚ùå Database sƒ±fƒ±rlama hatasƒ±: {e}")

def load_book_to_db(specialty: str, json_file_path: str) -> bool:
    """Bir kitabƒ±n chunk'larƒ±nƒ± database'e y√ºkle"""
    try:
        # JSON dosyasƒ±nƒ± oku
        with open(json_file_path, 'r', encoding='utf-8') as f:
            chunks = json.load(f)
        
        # ChromaDB'yi ba≈ülat
        _, coll = initialize_chroma()
        if coll == "error":
            print(f"‚ùå ChromaDB hatasƒ±")
            return False
        
        documents = []
        metadatas = []
        ids = []
        
        print(f"üìö {specialty} kitabƒ± y√ºkleniyor: {len(chunks)} chunk")
        
        for i, chunk in enumerate(chunks):
            # Unique ID olu≈ütur
            chunk_id = f"{specialty}_{i}"
            
            # Document content
            content = chunk.get('content', chunk.get('text', ''))
            if not content:
                print(f"‚ö†Ô∏è Bo≈ü chunk atlanƒ±yor: {chunk_id}")
                continue
                
            documents.append(content)
            
            # Metadata olu≈ütur
            metadata = {
                "specialty": specialty,
                "book_title": chunk.get('book_title', f"{specialty.title()} Medical Book"),
                "page_number": str(chunk.get('page_number', chunk.get('page', 'Unknown'))),
                "chunk_index": i,
                "source_type": "medical_textbook"
            }
            metadatas.append(metadata)
            ids.append(chunk_id)
        
        # Batch olarak database'e ekle
        if documents:
            coll.add(
                documents=documents,
                metadatas=metadatas,
                ids=ids
            )
            print(f"‚úÖ {specialty} ba≈üarƒ±yla y√ºklendi: {len(documents)} chunk")
            return True
        else:
            print(f"‚ùå {specialty} i√ßin hi√ß ge√ßerli chunk bulunamadƒ±")
            return False
            
    except Exception as e:
        print(f"‚ùå {specialty} y√ºkleme hatasƒ±: {e}")
        return False

def load_all_medical_books(books_config: Dict[str, str]) -> Dict[str, bool]:
    """T√ºm kitaplarƒ± database'e y√ºkle"""
    results = {}
    
    print("üöÄ T√ºm medical kitaplar y√ºkleniyor...")
    print("=" * 50)
    
    for specialty, file_path in books_config.items():
        if os.path.exists(file_path):
            success = load_book_to_db(specialty, file_path)
            results[specialty] = success
        else:
            print(f"‚ùå Dosya bulunamadƒ±: {file_path}")
            results[specialty] = False
    
    print("=" * 50)
    print("üìä Y√ºkleme √ñzeti:")
    for specialty, success in results.items():
        status = "‚úÖ Ba≈üarƒ±lƒ±" if success else "‚ùå Hatalƒ±"
        print(f"  {specialty}: {status}")
    
    return results

def query_db_by_specialty(query: str, specialty: str = None, n_results: int = 3) -> Dict:
    """Specialty'ye g√∂re filtrelenmi≈ü sorgu"""
    try:
        _, coll = initialize_chroma()
        if coll == "error":
            return {"documents": [], "metadatas": []}
        
        # Metadata filtreleme
        where_filter = None
        if specialty:
            where_filter = {"specialty": specialty}
        
        results = coll.query(
            query_texts=[query], 
            n_results=n_results,
            where=where_filter
        )
        
        return results
    except Exception as e:
        print(f"‚ùå Database sorgu hatasƒ±: {e}")
        return {"documents": [], "metadatas": []}

def get_database_info() -> Dict:
    """Database bilgilerini getir"""
    try:
        _, coll = initialize_chroma()
        if coll == "error":
            return {"error": "ChromaDB kullanƒ±lamƒ±yor"}
        
        # T√ºm metadatalarƒ± al
        results = coll.get()
        
        if not results.get("metadatas"):
            return {"total_chunks": 0, "specialties": []}
        
        # Specialty'leri say
        specialties = {}
        for metadata in results["metadatas"]:
            specialty = metadata.get("specialty", "unknown")
            specialties[specialty] = specialties.get(specialty, 0) + 1
        
        return {
            "total_chunks": len(results["metadatas"]),
            "specialties": specialties,
            "available_books": list(specialties.keys())
        }
    except Exception as e:
        return {"error": f"Database bilgi alma hatasƒ±: {e}"}

def add_to_db(doc_id, content):
    """Eski API - geriye uyumluluk i√ßin"""
    print("‚ö†Ô∏è add_to_db deprecated. Use load_book_to_db instead.")
    return False

def query_db(query):
    """Eski API - geriye uyumluluk i√ßin"""
    results = query_db_by_specialty(query)
    if results.get("documents") and results["documents"][0]:
        return results["documents"][0][0]
    return ""

def translate_text(text: str, target_language: str = "en", model_name: str = "models/gemini-1.5-pro-latest") -> str:
    """
    Gemini ile √ßeviri yapan fonksiyon.
    """
    prompt = f"L√ºtfen ≈üu metni {target_language.upper()} diline √ßevir:\n\n{text}"
    return ask_gemini_api(prompt, model_name=model_name)


def ask_gemini_api(prompt: str, model_name: str = "models/gemini-1.5-pro-latest", max_tokens=500, temperature=0.7) -> str:
    api_key = os.getenv("GEMINI_API_KEY")
    if not api_key:
        raise RuntimeError("Gemini API anahtarƒ± bulunamadƒ±. L√ºtfen .env dosyasƒ±nƒ± kontrol edin.")

    genai.configure(api_key=api_key)
    
    try:
        # Modeli ba≈ülat (√∂rneƒüin gemini-pro kullanƒ±lƒ±yor)
        model = genai.GenerativeModel(model_name=model_name)

        # Prompt g√∂nder
        response = model.generate_content(
            prompt,
            generation_config={
                "temperature": temperature,
                "max_output_tokens": max_tokens
            }
        )

        return response.text.strip()

    except Exception as e:
        raise RuntimeError(f"Gemini SDK Hatasƒ±: {str(e)}")

def answer_question(question: str, specialty: str = None, model: str = "models/gemini-1.5-pro-latest") -> Dict:
    try:
        if "[ENDOCRINOLOGY]" in question:
            specialty = "endocrinology"
            question = question.replace("[ENDOCRINOLOGY]", "").strip()
        db_results = query_db_by_specialty(question, specialty, n_results=3)
        if not db_results.get("documents") or not db_results["documents"][0]:
            return {
                "answer": "√úzg√ºn√ºm, bu konuda bilgi bulamadƒ±m.",
                "source_metadata": None,
                "query_info": {
                    "specialty_filter": specialty,
                    "results_found": 0
                }
            }
        context = db_results["documents"][0][0]
        metadata = db_results["metadatas"][0][0] if db_results.get("metadatas") else {}
        prompt = f"""
Context: {context}

Question: {question}

Answer based on the medical context provided:
"""
        llm_answer = ask_gemini_api(prompt, model_name=model, max_tokens=500, temperature=0.7)
        book_title = metadata.get("book_title", "Unknown")
        page_number = metadata.get("page_number", "Unknown")
        answer_with_source = f"This information is from {book_title}'s {page_number}th page:\n\n{llm_answer}"
        return {
            "answer": answer_with_source,
            "source_metadata": {
                "book_title": book_title,
                "page_number": page_number,
                "specialty": metadata.get("specialty", "Unknown")
            },
            "query_info": {
                "specialty_filter": specialty,
                "results_found": len(db_results["documents"][0])
            }
        }
    except Exception as e:
        print(f"‚ùå answer_question hatasƒ±: {e}")
        return {
            "answer": f"Bir hata olu≈ütu: {str(e)}",
            "source_metadata": None,
            "query_info": None
        }


