import random
import json
import os
import time
from dotenv import load_dotenv
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.chains import ConversationChain
from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.schema import SystemMessage
from google.api_core.exceptions import ResourceExhausted
from langchain.memory import ConversationBufferMemory
import google.generativeai as genai

load_dotenv()
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")

# random hasta seÃ§imi
def load_random_patient(area: str, base_path="./patient_data"):
    path = os.path.join(base_path, area)
    print(f"YÃ¼klenmek istenen klasÃ¶r: {path}")

    if not os.path.exists(path):
        raise Exception(f"KlasÃ¶r bulunamadÄ±: {path}")

    files = [f for f in os.listdir(path) if f.endswith(".json")]
    if not files:
        raise Exception(f"{path} klasÃ¶rÃ¼nde json dosyasÄ± yok.")

    chosen = random.choice(files)
    print(f"SeÃ§ilen hasta dosyasÄ±: {area}/{chosen}")

    with open(os.path.join(path, chosen), 'r', encoding='utf-8') as f:
        data = json.load(f)

    cases = data.get("disease_info", {}).get("cases", [])
    if not cases:
        raise Exception("SeÃ§ilen dosyada hiÃ§ vaka bulunamadÄ±.")

    # Tek vaka varsa direkt onu al
    return cases[0]



# sistem promptu hazÄ±rlama
def create_system_prompt(patient_data, doctor_gender):
    profile = patient_data.get("patient_profile", {})

    name = profile.get("name", "Bilinmiyor")
    age = profile.get("age", "Bilinmiyor")
    gender = profile.get("gender", "Bilinmiyor")

    # YaÅŸ birimi opsiyonel
    age_unit = profile.get("age_unit", "")
    age_str = f"{age} {age_unit}".strip()

    # Semptomlar (sÃ¶zlÃ¼kse dÃ¼zleÅŸtir)
    symptoms_raw = profile.get("symptoms", {})
    if isinstance(symptoms_raw, dict):
        symptoms = ", ".join([f"{k}: {v}" for k, v in symptoms_raw.items()])
    else:
        symptoms = symptoms_raw or "BelirtilmemiÅŸ"

    # TÄ±bbi geÃ§miÅŸ
    history_raw = profile.get("medical_history")
    if isinstance(history_raw, list):
        history = ", ".join(history_raw)
    elif isinstance(history_raw, str):
        history = history_raw
    else:
        history = "Yok"

    # GÃ¼ncel hikaye (history)
    patient_story = profile.get("history", "BelirtilmemiÅŸ")

    # Vital bulgular
    vitals = profile.get("vital_signs", {})
    vitals_str = ", ".join([f"{k}: {v}" for k, v in vitals.items()]) if vitals else "Yok"

    # Fizik muayene
    physical = profile.get("physical_exam", {})
    physical_str = ", ".join([f"{k}: {v}" for k, v in physical.items()]) if physical else "Yok"

    # Laboratuvar
    lab = profile.get("laboratory", {})
    lab_str = ", ".join([f"{k}: {v}" for k, v in lab.items()]) if lab else "Yok"

    # GÃ¶rÃ¼ntÃ¼leme verisi varsa
    images = profile.get("imaging", {})
    image_str = ", ".join([f"{k}: {v}" for k, v in images.items()]) if images else "Yok"

    # Ä°laÃ§lar
    meds = profile.get("medications", [])
    meds_str = ", ".join(meds) if meds else "Yok"

    # Aile Ã¶ykÃ¼sÃ¼
    family_history_raw = profile.get("family_history")
    if isinstance(family_history_raw, list):
        family_history = ", ".join(family_history_raw)
    elif isinstance(family_history_raw, str):
        family_history = family_history_raw
    else:
        family_history = "Yok"

    # Sosyal Ã¶ykÃ¼
    social = profile.get("social_history", [])
    social_str = ", ".join(social) if social else "Yok"

    # Doktora hitap
    honorific = "Doktor HanÄ±m" if doctor_gender == "kadÄ±n" else "Doktor Bey"


    prompt = f"""
    Sen gerÃ§ek bir hastasÄ±n. Bir tÄ±p Ã¶ÄŸrencisi seninle gÃ¶rÃ¼ÅŸme yapÄ±yor. 
    Doktorun cinsiyeti: {doctor_gender}. Ona hitap ederken "{honorific}" ÅŸeklinde seslen.

    AÅŸaÄŸÄ±daki bilgiler sana aittir:

    ğŸ‘¤ **Ad**: {name}  
    ğŸ“… **YaÅŸ**: {age_str}  
    ğŸš» **Cinsiyet**: {gender}  
    ğŸ¤’ **Semptomlar**: {symptoms} 
    GÃ¼ncel Hikaye: {patient_story} 
    ğŸ“– **TÄ±bbi GeÃ§miÅŸ**: {history}  
    ğŸ‘¨â€ğŸ‘©â€ğŸ‘§ **Aile Ã–ykÃ¼sÃ¼**: {family_history}  
    ğŸ§¬ **Sosyal Ã–ykÃ¼**: {social_str}  
    ğŸ’Š **KullanÄ±lan Ä°laÃ§lar**: {meds_str}  
     
    HastalÄ±k adÄ±nÄ± sakla ve sadece Ã¶ÄŸrenci sorduÄŸunda cevapla.
    SorularÄ± gerÃ§ek bir hasta gibi yanÄ±tla.
    Gereksiz bilgi verme, sorulmadÄ±kÃ§a teÅŸhisi sÃ¶yleme. 
    """
    return prompt.strip()


# HafÄ±za oluÅŸturma fonksiyonu
def create_memory():
    return ConversationBufferMemory(return_messages=True)


# LLM modelini baÅŸlatma fonksiyonu
def initialize_llm(model_name="models/gemini-1.5-pro-latest", temperature=0.7):
    return ChatGoogleGenerativeAI(
        model=model_name,
        temperature=temperature,
        google_api_key=GOOGLE_API_KEY
    )


# Chat modeli ve memory ayarlama
def create_conversation_chain(llm_instance, system_prompt, memory):
    prompt = ChatPromptTemplate.from_messages([
        SystemMessage(content=system_prompt),
        MessagesPlaceholder(variable_name="history"),
        ("human", "{input}")
    ])
    chain = ConversationChain(
        llm=llm_instance,
        prompt=prompt,
        memory=memory,
        verbose=True
    )
    return chain

def list_supported_models():
    try:
        genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))
        print("Desteklenen Modeller:")
        for m in genai.list_models():
            # 'generateContent' metodunu destekleyen modelleri filtreliyoruz
            if 'generateContent' in m.supported_generation_methods:
                print(f"Model AdÄ±: {m.name}, AÃ§Ä±klama: {m.description}")
    except Exception as e:
        print(f"Hata oluÅŸtu: {e}")

def get_response(user_input, memory, llm_instance, system_prompt):
    try:
        chain = create_conversation_chain(llm_instance, system_prompt, memory)
        response = chain.predict(input=user_input)
        return response, chain.memory
    except Exception as e:
        return f"Hata oluÅŸtu: {str(e)}", memory
